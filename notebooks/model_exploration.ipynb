# ðŸŒŠ Aqualyx AI â€“ Model Exploration Notebook

This notebook demonstrates:

- Data loading & preprocessing
- Feature engineering for time-series water usage
- Leak simulation strategy
- Model training (Random Forest)
- Evaluation metrics
- Feature importance analysis
- Model export for production use

Author: Ankit Kumar  
Project: Aqualyx AI  


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import joblib

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report
)

plt.style.use("ggplot")


df = pd.read_csv("../data/synthetic_dataset.csv")
df.head()


print("Dataset Shape:", df.shape)
print("\nMissing Values:\n", df.isnull().sum())
print("\nData Types:\n", df.dtypes)


df["leak"].value_counts().plot(kind="bar")
plt.title("Leak vs Normal Distribution")
plt.show()


df["rolling_mean"] = df["usage_liters"].rolling(window=3).mean()
df["rolling_std"] = df["usage_liters"].rolling(window=3).std()
df["usage_change"] = df["usage_liters"].pct_change()

df.fillna(0, inplace=True)
df.head()


features = [
    "usage_liters",
    "rolling_mean",
    "rolling_std",
    "usage_change"
]

X = df[features]
y = df["leak"]


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Train size:", X_train.shape)
print("Test size:", X_test.shape)


model = RandomForestClassifier(
    n_estimators=150,
    max_depth=8,
    random_state=42
)

model.fit(X_train, y_train)


y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]


accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)


cm = confusion_matrix(y_test, y_pred)

sns.heatmap(cm, annot=True, fmt="d")
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()


metrics = {
    "accuracy": float(accuracy),
    "precision": float(precision),
    "recall": float(recall),
    "f1_score": float(f1)
}

with open("../backend/ml/metrics.json", "w") as f:
    json.dump(metrics, f, indent=4)

metrics


joblib.dump(model, "../backend/ml/model.pkl")
print("Model saved successfully!")
